{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50665be2-5d87-4233-b0e2-5b59f8e2ade5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os  \n",
    "import docx\n",
    "import re\n",
    "from docx import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "048c0370-efbe-4015-a2a4-3c3b20083522",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.to_docx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "68541be1-d515-4f14-9082-9529ba917771",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from docx import Document\n",
    "from tqdm import tqdm  # 导入 tqdm\n",
    "\n",
    "def to_docx(main_path, save_dir, middle_path='content'):\n",
    "    \n",
    "    # 获取该文件夹下的所有文件和文件夹名称  \n",
    "    entries = os.listdir(main_path)  \n",
    "    # 过滤出文件夹名称  \n",
    "    folders = [entry for entry in entries if os.path.isdir(os.path.join(main_path, entry))]  \n",
    "    if '.git' in folders:\n",
    "        folders.remove('.git')\n",
    "        \n",
    "    if not os.path.exists(save_dir):\n",
    "        # 创建文件夹  \n",
    "        os.makedirs(save_dir)\n",
    "        \n",
    "    for book_name in folders:\n",
    "        path = os.path.normpath(os.path.join(main_path, book_name, middle_path))  # 获取路径\n",
    "        tex_files = [filename for filename in os.listdir(path) if filename.endswith('.tex') and (filename.startswith('chap') or filename.startswith('part'))]\n",
    "\n",
    "        # 使用 tqdm 包装 tex_files 以显示进度条\n",
    "        for file in tqdm(tex_files, desc=f'Processing {book_name}'):\n",
    "            full_path = os.path.join(path, file)\n",
    "            # 读取文件内容\n",
    "            with open(full_path, 'r', encoding='utf-8') as f:\n",
    "                content = f.read()\n",
    "\n",
    "            # 去除多余的换行\n",
    "            cleaned_content = re.sub(r'\\n+', '\\n\\n', content).strip()\n",
    "\n",
    "            # 将两个英文单词之间的换行替换为空格\n",
    "            cleaned_content = re.sub(r'([A-Za-z]+)\\n+([A-Za-z]+)', r'\\1 \\2', cleaned_content)\n",
    "            \n",
    "            # 处理\"{Hp}\"或\"{HP}\"后面可能跟有无意义换行符的情况\n",
    "            cleaned_content = re.sub(r'(\\{[Hh][Pp]\\})\\n+', r'\\1', cleaned_content)\n",
    "\n",
    "            # 创建一个新的 Word 文档\n",
    "            doc = Document()\n",
    "\n",
    "            for line in cleaned_content.splitlines():\n",
    "                if line.strip():\n",
    "                    doc.add_paragraph(line)\n",
    "\n",
    "            output_folder = f'{save_dir}/{book_name}'\n",
    "            if not os.path.exists(output_folder):\n",
    "                # 创建文件夹  \n",
    "                os.makedirs(output_folder)\n",
    "\n",
    "            doc.save(os.path.join(output_folder, f'{file[:-4]}.docx'))\n",
    "\n",
    "            \n",
    "# main_path = '../Git_projects/medical-books/'  \n",
    "# middle_path = 'content'  # 去掉斜杠，放在最后拼接\n",
    "# save_dir = 'docxs'\n",
    "\n",
    "# to_docx(main_path=main_path, save_dir=save_dir, middle_path=middle_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1ac54b17-6f34-4807-8e6e-1d810986681b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.read_docx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1ec45a70-2204-4917-89f0-888cc6a68aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_docx(file_path):\n",
    "    doc = Document(file_path)\n",
    "    text = []\n",
    "    for i in doc.paragraphs:\n",
    "        text.append(i.text)\n",
    "    return '\\n\\n'.join(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "147fa606-7b9a-4f9d-885d-cc72cce775c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.filter_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "12c9e24a-3297-4922-884d-6c9ca374f696",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_content(content):\n",
    "    \"\"\"\n",
    "    过滤掉列表中的内容，包括：\n",
    "    1. 以 '\\\\begin' 开头并以 '\\\\end' 结尾的块内容（支持嵌套的情况）。\n",
    "    2. 以 '\\\\protect' 开头的行。\n",
    "    \n",
    "    参数:\n",
    "    content (list): 包含字符串的列表，每个字符串可能是你要处理的行或块。\n",
    "    \n",
    "    返回:\n",
    "    list: 过滤后的列表。\n",
    "    \"\"\"\n",
    "    filtered_content = []\n",
    "    skip_block = 0  # 跟踪嵌套的 \\\\begin 和 \\\\end\n",
    "    for item in content:\n",
    "        # 如果遇到 \\\\begin，则增加嵌套层级\n",
    "        if '\\\\begin{' in item:\n",
    "            skip_block += 1\n",
    "        \n",
    "        # 如果在跳过状态中，直接跳过当前块内的内容\n",
    "        if skip_block > 0:\n",
    "            # 如果遇到 \\\\end，则减少嵌套层级\n",
    "            if '\\\\end{' in item:\n",
    "                skip_block -= 1\n",
    "            continue  # 跳过当前块内的内容\n",
    "        \n",
    "        # 如果当前行以 \\\\protect 开头，则跳过该行\n",
    "        if item.startswith('\\\\protect'):\n",
    "            continue\n",
    "        \n",
    "        # 如果不在跳过状态，则添加当前行\n",
    "        filtered_content.append(item)\n",
    " \n",
    "    return filtered_content "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fef77c52-d75a-480a-ba10-7c4bd392f054",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.to_tex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d58ad504-b8e5-4e62-8ee0-5da6e8167efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from docx import Document\n",
    "from tqdm import tqdm  # 导入 tqdm\n",
    "\n",
    "def to_tex(path, save_dir):\n",
    "    \n",
    "    # 获取文件夹名称  \n",
    "    entries = os.listdir(path)  \n",
    "    # 过滤出文件夹名称  \n",
    "    if \".ipynb_checkpoints\" in entries:\n",
    "        entries.remove('.ipynb_checkpoints')\n",
    "        \n",
    "    if not os.path.exists(save_dir):\n",
    "        # 创建文件夹  \n",
    "        os.makedirs(save_dir)\n",
    "        \n",
    "    for book_name in entries:\n",
    "        all_path = os.path.normpath(os.path.join(path, book_name))  # 获取单一文件夹内的所有docx根路径\n",
    "        book_files = [filename for filename in os.listdir(all_path) if filename.endswith('.docx')]  # 将docx名字存入列表\n",
    "\n",
    "        # 使用 tqdm 包装 tex_files 以显示进度条\n",
    "        for file in tqdm(book_files, desc=f'Processing {book_name}'):\n",
    "            full_path = os.path.join(all_path, file)  # 将根路径与docx名字拼接起来\n",
    "            # 读取文件内容\n",
    "            content = read_docx(full_path)\n",
    "            content = content.split('\\n\\n')\n",
    "            content = filter_content(content)\n",
    "            text = '\\n'.join(content)\n",
    "            \n",
    "            \n",
    "            output_folder = f'{save_dir}/{book_name}'\n",
    "            if not os.path.exists(output_folder):\n",
    "                # 创建文件夹  \n",
    "                os.makedirs(output_folder)\n",
    "\n",
    "            with open(f'./{output_folder}/{file[:-5]}.tex', 'w', encoding='utf-8') as f:\n",
    "                f.write(text)\n",
    "\n",
    "# path = 'docxs'\n",
    "# save_dir = 'texs'\n",
    "# to_tex(path, save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "504b3994-2a9f-498a-b0ab-10878bde90ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.read_tex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5b710f48-a168-45da-881c-1bb29882bbce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pylatexenc.latex2text import LatexNodes2Text\n",
    "import re\n",
    "from collections import defaultdict\n",
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "237fe475-bc55-4c9a-b05c-217a2ab8f260",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_tex(path):\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        content = f.read()\n",
    "    \n",
    "    content = LatexNodes2Text().latex_to_text(content)\n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "238766ca-8e1a-4474-8a6b-7c9032032983",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.add_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "68bf3659-f915-4cfd-9201-4ebf1c0b0dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_content(lst, book_name, chapter, section, subsection, subsubsection, content, subsubsubsection=None,):\n",
    "    lst.append({\n",
    "        'book_name': book_name,\n",
    "        'chapter': chapter,\n",
    "        'section': section,\n",
    "        'subsection': subsection,\n",
    "        'subsubsection': subsubsection,\n",
    "        'subsubsubsection': subsubsubsection,\n",
    "        'content': content,\n",
    "    })\n",
    "    return lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "61d40391-820f-43e4-986e-be4482e3d604",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7.parase_document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "2f741168-76d8-419c-bb9e-7d5fc3e07730",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 去除换行，根据以\"PART\"为章节或是以\"CHAPTER\"为章节进行针对处理\n",
    "def parse_document(book_name, text):\n",
    "    # 去除所有换行符并分段\n",
    "    text = text.replace('\\n', ' ').strip()  # 替换所有换行符为空格\n",
    "    segments = text.split('  ')  # 根据两个空格分段\n",
    "    result = []\n",
    "    book_name = book_name\n",
    "    chapter = None\n",
    "    section = None\n",
    "    subsection = None\n",
    "    subsubsection = None\n",
    "    subsubsubsection = None  # 独属于PART\n",
    "    content = None\n",
    "\n",
    "    # 判断是否是 PART 类型章节\n",
    "    is_part = segments[0].startswith(\"PART\")\n",
    "    is_section_part = True  # 判断列表内容中是否有\"section\"作为一级标题\n",
    "    \n",
    "    for idx, line in enumerate(segments):\n",
    "        line = line.strip()\n",
    "        # print(\"输出内容\", line)\n",
    "        \n",
    "        # 处理PART章节逻辑\n",
    "        if is_part:\n",
    "            # for i in segments:\n",
    "            #     # 如果当中出现以\"section\"为一级标题\n",
    "            #     i = i.strip()\n",
    "            #     if i.startswith(\"§\") and not i.startswith(\"§.§\") and not i.startswith(\"§.§.§\"):\n",
    "            #         is_section_part = True\n",
    "            #         break # 跳出循环即可\n",
    "            # print(is_section_part)\n",
    "            # 如果有\"section\"\n",
    "            if is_section_part:\n",
    "                if line.startswith(\"PART\"): \n",
    "                    if idx == 0:\n",
    "                        temp = segments[1].strip().split(' ')\n",
    "                        chapter = temp[0]\n",
    "                        if len(temp) > 1:  # 如果能两层\n",
    "                            content = temp[1]\n",
    "                            # print(content)\n",
    "                    continue\n",
    "                elif line.startswith(\"CHAPTER\"):  # PART下的CHAPTER为一级标题\n",
    "                    if section != line.replace(\"CHAPTER:\", \"\").strip():  # 如果出现了新的标题\n",
    "                        if content:\n",
    "                            result = add_content(\n",
    "                                lst=result, book_name = book_name, chapter=chapter, subsection=subsection, subsubsection=subsubsection\n",
    "                                , subsubsubsection=subsubsubsection, content=content, section=section\n",
    "                            )\n",
    "                            content = None  # 置空\n",
    "                        subsection = subsubsection = subsubsubsection = None  # 清空子标题\n",
    "                            \n",
    "                    section = line.replace(\"CHAPTER:\", \"\").strip()\n",
    "                    content = None  # 一级标题下的内容清空\n",
    "                    continue\n",
    "                elif line.startswith(\"§\") and not line.startswith(\"§.§\") and not line.startswith(\"§.§.§\"):  # PART下的§为二级标题\n",
    "                    if subsection != line.replace(\"§\", \"\").strip():  # 如果出现了新的标题\n",
    "                        if content:\n",
    "                            result = add_content(\n",
    "                                lst=result, book_name= book_name, chapter=chapter, subsection=subsection, subsubsection=subsubsection\n",
    "                                , subsubsubsection=subsubsubsection, content=content, section=section\n",
    "                            )\n",
    "                            content = None  # 置空\n",
    "                        subsubsection = subsubsection = None  # 清空子标题\n",
    "                        \n",
    "                    subsection = line.replace(\"§\", \"\").strip()\n",
    "                    continue\n",
    "                elif line.startswith(\"§.§\") and not line.startswith(\"§.§.§\"):  # PART下的§.§为三级标题\n",
    "                    if subsubsection != line.replace(\"§.§\", \"\").strip():\n",
    "                        \n",
    "                        if content:\n",
    "                            result = add_content(\n",
    "                                lst=result, book_name= book_name, chapter=chapter, subsection=subsection, subsubsection=subsubsection\n",
    "                                , subsubsubsection=subsubsubsection, content=content, section=section\n",
    "                            )\n",
    "                            content = None  # 置空\n",
    "                        subsubsubsection = None\n",
    "                        \n",
    "                    subsubsection = line.replace(\"§.§\", \"\").strip()\n",
    "                    continue\n",
    "                elif line.startswith(\"§.§.§\"):\n",
    "                    if subsubsubsection != line.replace(\"§.§.§\", \"\").strip():\n",
    "                        if content:\n",
    "                            result = add_content(\n",
    "                                    lst=result, book_name = book_name, chapter=chapter, subsection=subsection, subsubsection=subsubsection\n",
    "                                    , subsubsubsection=subsubsubsection, content=content, section=section\n",
    "                                )\n",
    "                            content = None  # 置空\n",
    "                        \n",
    "                    subsubsubsection = line.replace(\"§.§.§\", \"\").strip()\n",
    "                    continue\n",
    "                else:\n",
    "                    # 如果正好对上了\"PART\"的逻辑\n",
    "                    if line.split(' ')[0] == chapter:\n",
    "                        continue\n",
    "                    else:\n",
    "                        if content:  # 如果已经有了content，则添加\n",
    "                            content += line.strip()\n",
    "                            continue\n",
    "                        else:\n",
    "                            content = line.strip()\n",
    "                            \n",
    "\n",
    "        # 处理CHAPTER章节逻辑\n",
    "        else:\n",
    "            if line.startswith(\"CHAPTER\"):\n",
    "                chapter = line.replace(\"CHAPTER:\", \"\").strip()\n",
    "                content = None  # 章节内容清空\n",
    "                continue\n",
    "            elif line.startswith(\"§\") and not line.startswith(\"§.§\") and not line.startswith(\"§.§.§\"):  # CHAPTER下的§为一级标题\n",
    "                if section != line.replace(\"§\", \"\").strip():  # 如果出现了新的一级标题则清空二级标题和三级标题\n",
    "                    if content:\n",
    "                        result = add_content(\n",
    "                                lst=result, book_name= book_name, chapter=chapter, subsection=subsection, subsubsection=subsubsection\n",
    "                                , subsubsubsection=subsubsubsection, content=content, section=section\n",
    "                            )\n",
    "                        content = None  # 置空\n",
    "                    subsection = None\n",
    "                    subsubsection = None\n",
    "                    \n",
    "                section = line.replace(\"§\", \"\").strip()\n",
    "                content = None  # 一级标题下的内容清空\n",
    "                continue\n",
    "            elif line.startswith(\"§.§\") and not line.startswith(\"§.§.§\"):  # CHAPTER下的§.§为二级标题\n",
    "                if subsection != line.replace(\"§.§\", \"\").strip():  # 如果出现了新的二级标题则清空二级标题和三级标题\n",
    "                    if content:\n",
    "                        result = add_content(\n",
    "                                lst=result, book_name= book_name, chapter=chapter, subsection=subsection, subsubsection=subsubsection\n",
    "                                , subsubsubsection=subsubsubsection, content=content, section=section\n",
    "                            )\n",
    "                        content = None  # 置空\n",
    "                    subsubsection = None\n",
    "                    \n",
    "                subsection = line.replace(\"§.§\", \"\").strip()\n",
    "                content = None\n",
    "                continue\n",
    "            elif line.startswith(\"§.§.§\"):  # CHAPTER下的§.§.§为三级标题\n",
    "                if subsubsection != line.replace(\"§.§.§\", \"\").strip():\n",
    "                    if content:\n",
    "                        result = add_content(\n",
    "                                lst=result, book_name= book_name, chapter=chapter, subsection=subsection, subsubsection=subsubsection\n",
    "                                , subsubsubsection=subsubsubsection, content=content, section=section\n",
    "                            )\n",
    "                        content = None  # 置空\n",
    "                        \n",
    "                subsubsection = line.replace(\"§.§.§\", \"\").strip()\n",
    "                continue\n",
    "            else:\n",
    "                if content:\n",
    "                    content += line.strip()\n",
    "                    continue\n",
    "                else:\n",
    "                    content = line.strip()\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "92a04287-b365-45ea-99c1-174bf9113802",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8.know_extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c30a87c-49f9-4d9e-bebe-c0e6c21bbcd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = './texs'\n",
    "book_path = os.listdir(folder_path)\n",
    "path = []\n",
    "for i in book_path:\n",
    "    path.append(os.path.normpath(os.path.join(folder_path, i)))\n",
    "    \n",
    "lst = []\n",
    "\n",
    "for book in path:\n",
    "    tqdm_name = book.split('/')[1]\n",
    "    files = [filename for filename in os.listdir(book) if filename.endswith('.tex')]\n",
    "    \n",
    "    for filename in tqdm(files, desc=f'Procession book: {tqdm_name}'):\n",
    "        file_path = os.path.join(book, filename)\n",
    "        \n",
    "        content = read_tex(file_path)\n",
    "        content = parse_document(tqdm_name, content)\n",
    "        lst.extend(content)\n",
    "        \n",
    "content = lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "0a6bc50f-af48-4ca7-ad6a-7c4dbc01d0d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from docx import Document\n",
    "\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain_core.output_parsers import StrOutputParser,JsonOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate,MessagesPlaceholder\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "from docx import Document\n",
    "import json\n",
    "from tqdm import tqdm  \n",
    "import concurrent.futures\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "93e9d4b4-63d5-415f-8fa9-3599eb09a1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 确保输出是有效的JSON格式\n",
    "systemContent = r\"\"\"你是我的医学知识提取助理，负责从医学文件中提取结构化的医学知识点。每条知识点应围绕同一医学概念，将密切关联的知识点合并为一个独立的完整条目。\n",
    "\n",
    "要求如下：\n",
    "- 输入内容为一个包含以下字段的字典：'book_name'（书名）、'chapter'（章节）、'section'（一级标题）、'subsection'（二级标题）、'subsubsection'（三级标题）、'subsubsubsection'（四级标题）、'content'（内容）。\n",
    "- 提取具体的医学知识点，专注于病理学定义、影像学特征、临床症状等，不包含推断、诊治内容或流行病学数据。\n",
    "- 若存在多个关联性强的知识点（例如围绕 GERD、GU/DU 等主题），应将它们合并为一个结构化条目，保持内容的连贯性。\n",
    "- 每条提取的知识点应独立且完整，避免模糊表达，但内容相近的知识点应整合在一起形成逻辑完整的信息。\n",
    "- 输出格式为 JSON 列表，其中每个条目为一个字典，包含一条知识点信息。\n",
    "- 输出中应仅包含 'knowledge' 字段，忽略输入中的其他标题字段。\n",
    "\n",
    "输入案例:\n",
    "{knowledge}\n",
    "\n",
    "输出案例：\n",
    "[\n",
    "    {{\"knowledge\": \"中耳胆脂瘤是指在中耳腔内形成的囊性病变，通常由表皮细胞异常增生引起。MRI影像学特征包括：T1加权像（T1WI）呈中等信号强度，T2加权像（T2WI）显示不均匀高信号，并且弥散加权成像（DWI）上病灶的弥散受限明显，增强扫描无强化表现。\"}},\n",
    "    {{\"knowledge\": \"GERD相关症状包括声音嘶哑、夜间睡眠障碍、咽炎、耳痛和龈炎等。这些症状可能与胃酸反流及其对周围组织的影响有关。\"}}\n",
    "]\n",
    "\"\"\"\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [(\"system\", systemContent), (\"user\", \"{text}\")]\n",
    ")\n",
    "\n",
    "model = Ollama(model=\"qwen2.5:14b-32k\", temperature=0.0)\n",
    "parser = JsonOutputParser()\n",
    "chain = prompt_template | model | parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3762a81b-9ad8-4992-aee2-0ee7159e85a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 确保文件夹存在\n",
    "os.makedirs('./know', exist_ok=True)\n",
    "\n",
    "if not os.path.exists('./know/knowledge.json'):\n",
    "    with open('./know/knowledge.json', 'w') as f:\n",
    "        json.dump([], f)\n",
    "\n",
    "# 读取现有数据\n",
    "with open('./know/knowledge.json', 'r') as f:\n",
    "    responses = json.load(f)\n",
    "\n",
    "for i in tqdm(content):\n",
    "    time = 0\n",
    "    generate_time = 0\n",
    "    while True:\n",
    "        try:     \n",
    "            knowledge = {\n",
    "                'book_name': i['book_name'],\n",
    "                'chapter': i['chapter'],\n",
    "                'section': i['section'],\n",
    "                'subsection': i['subsection'],\n",
    "                'subsubsection': i['subsubsection'],\n",
    "                'subsubsubsection': i['subsubsubsection'],\n",
    "                'content': i['content']\n",
    "            }\n",
    "            response = chain.invoke({'knowledge': knowledge, 'text': knowledge})\n",
    "            if isinstance(response, list):\n",
    "                if response:\n",
    "                    # print(response)\n",
    "                    for i in response:\n",
    "                        responses.append(i)\n",
    "                    \n",
    "                    # 立即写入文件\n",
    "                    with open('./know/knowledge.json', 'w') as f:\n",
    "                        json.dump(responses, f, ensure_ascii=False, indent=4)\n",
    "                    break\n",
    "                else:\n",
    "                    break\n",
    "            else:\n",
    "                generate_time += 1\n",
    "                if generate_time == 50:\n",
    "                    break\n",
    "        except Exception as e:\n",
    "            time+=1\n",
    "            print(str(e))\n",
    "            if time == 5:\n",
    "                b = i[\"book_name\"]\n",
    "                c = i[\"chapter\"]\n",
    "                sec = i[\"section\"]\n",
    "                subsec = i[\"subsection\"]\n",
    "                subsubsec = i[\"subsubsection\"]\n",
    "                subsubsubsec = i[\"subsubsubsection\"]\n",
    "                print(f\"{b}_{c}_{sec}_{subsec}_{subsubsec}_{subsubsubsec} happen error\")\n",
    "                break"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "5bd60f8a-df82-4902-9d13-9bb000690000"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "codellm",
   "language": "python",
   "name": "codellm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
